from django.shortcuts import render
from django.http import HttpResponse
from django.http import JsonResponse
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from sklearn.linear_model import SGDClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import pickle 


'''
def home(request):
    return HttpResponse("Hello, Django!")

'''

def mal(request):
    
    X_dataTest = np.array([
        ['android/media/MediaPlayer->start android/app/Activity->setContentView android/os/Vibrator->cancel',
     'android.permission.VIBRATE', 'android.hardware.touchscreen',
     'android.intent.action.MAIN android.intent.category.LAUNCHER',
     '.FlAndroidApp FlAndroidApp', 'getSystemService',
     'android.permission.INTERNET android.permission.VIBRATE android.permission.WAKE_LOCK']
    ])

    def feature_extraction(X_dataTest):

        from sklearn.feature_extraction.text import TfidfVectorizer
    # initialize X_train and X_test
        X_test = []
        models = []
    # iterate over each column of X_dataTrain
        for i in range(X_dataTest.shape[1]):
        # train feature word2vec using column i
            print("Training column {}...".format(i))
        # get train and test data
            test_data = X_dataTest[:,i]
        # initialize and train model
            tfidf = TfidfVectorizer(max_features=100)
            tfidf.fit(test_data)
        # transform train and test texts to w2v mean
            test_tfidf = tfidf.transform(test_data).todense()
        # if first execution, save only features
            if len(X_test) == 0:
                X_test = test_tfidf
        # concatenate existing features
            else:
                X_test = np.concatenate((X_test, test_tfidf), axis=1)
                models.append(tfidf)
        return(X_test)
    X_test = feature_extraction(X_dataTest)

    def normalization(X_test):
        from sklearn.preprocessing import MinMaxScaler
        X_test=np.asarray(X_test)
        scaler = MinMaxScaler()
        scaler.fit(X_test)
        XX_test = scaler.transform(X_test)
        return( XX_test)
    
    XX_test = normalization( X_test)
    print(XX_test)
     
    #model= pickle.load(open('ml-dl_model.pkl','rb'))


    def predict(XX_test):
        model= pickle.load(open('ml-dl_model.pkl','rb'))
        #if request.method == 'POST':
        #data = request.POST.get('data')
        predictions = model.predict(XX_test)
        confidence_level = model.predict_proba(XX_test)
        confidence_levels = confidence_level[:, 0]
        confidence_levels_percent=confidence_levels*100
        confidence_levels_percent = [round(x, 1) for x in confidence_levels_percent]
    
    # Format predictions and confidence level into a response
        response = {
            'predictions': predictions.tolist(),
            'confidence_level': confidence_levels_percent
        }
    
    # Return the response as JSON
        print(response['predictions'])
        print(response['confidence_level'])
    predict(XX_test)
    return HttpResponse("Malware") 
